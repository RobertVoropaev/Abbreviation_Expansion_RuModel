{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 14 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 1\n",
    "random.seed(SEED)\n",
    "\n",
    "pd.set_option('display.max_colwidth', 255)\n",
    "tqdm.pandas()\n",
    "pandarallel.initialize(progress_bar=True, nb_workers=14, use_memory_fs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbr = pd.read_csv(\"../data/abbr.csv\")\n",
    "lenta = pd.read_csv(\"../data/lenta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbbrInfo:\n",
    "    def __init__(self, abbr_id, abbr, abbr_count):\n",
    "        self.abbr_id = abbr_id \n",
    "        self.abbr = abbr\n",
    "        self.abbr_count = abbr_count\n",
    "\n",
    "ABBR_LIST_KEY = \"<ABBR_LIST_KEY>\"\n",
    "        \n",
    "def create_abbr_tree(abbr, abbr_list_key = ABBR_LIST_KEY):        \n",
    "    tree = {}\n",
    "    for norm_desc, norm_abbr, abbr_id, abbr_count in abbr[[\"desc_norm\", \n",
    "                                                           \"abbr_norm\", \n",
    "                                                           \"abbr_id\", \n",
    "                                                           \"abbr_count\"]].values:\n",
    "        words = norm_desc.split(\" \")\n",
    "\n",
    "        curr_tree = tree\n",
    "        for word in words:\n",
    "            if word not in curr_tree:\n",
    "                curr_tree[word] = {}\n",
    "            curr_tree = curr_tree[word]\n",
    "\n",
    "\n",
    "        if abbr_list_key not in curr_tree:\n",
    "            curr_tree[abbr_list_key] = []\n",
    "\n",
    "        curr_tree[abbr_list_key].append(AbbrInfo(abbr_id, norm_abbr, abbr_count))\n",
    "    return tree\n",
    "\n",
    "abbr_tree = create_abbr_tree(abbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTSIDE_LABEL = \"_\"\n",
    "BEGIN_LABEL = \"B\"\n",
    "END_LABEL = \"E\"\n",
    "INSIDE_LABEL = \"I\"\n",
    "ONE_WORD_LABEL = \"W\"\n",
    "\n",
    "def choice_abbr(abbr_list: list, \n",
    "                weighted_choice: bool = True, \n",
    "                add_to_zeros: float = 0):\n",
    "    abbr_counts = []\n",
    "    \n",
    "    if weighted_choice:\n",
    "        for abbr_info in abbr_list:\n",
    "            cnt = abbr_info.abbr_count\n",
    "            if cnt == 0:\n",
    "                cnt = add_to_zeros\n",
    "            abbr_counts.append(cnt)\n",
    "    else:\n",
    "        abbr_counts = None\n",
    "    \n",
    "    \n",
    "    return random.choices(abbr_list, weights=abbr_counts, k=1)[0]\n",
    "\n",
    "def get_text_labels(text, \n",
    "                    abbr_tree, \n",
    "                    weighted_choice: bool = None, \n",
    "                    add_to_zeros: float = None):\n",
    "    text = text.split(\" \")\n",
    "    labels = [OUTSIDE_LABEL for i in range(len(text))]\n",
    "\n",
    "    curr_node = abbr_tree\n",
    "    desc_start = None\n",
    "\n",
    "    word_i = 0\n",
    "    while word_i < len(text):\n",
    "        curr_i = word_i\n",
    "        while curr_i < len(text) and text[curr_i] in curr_node:\n",
    "            curr_node = curr_node[text[curr_i]]\n",
    "            curr_i += 1\n",
    "\n",
    "        if ABBR_LIST_KEY in curr_node: \n",
    "\n",
    "            abbr_id = choice_abbr(curr_node[ABBR_LIST_KEY], weighted_choice, add_to_zeros).abbr_id\n",
    "\n",
    "            labels[word_i] = f\"{BEGIN_LABEL}-{abbr_id}\"\n",
    "            for j in range(word_i + 1, curr_i - 1): \n",
    "                labels[j] = f\"{INSIDE_LABEL}-{abbr_id}\"\n",
    "            labels[curr_i - 1] = f\"{END_LABEL}-{abbr_id}\"\n",
    "\n",
    "            if word_i == curr_i - 1:\n",
    "                labels[word_i] = f\"{ONE_WORD_LABEL}-{abbr_id}\"\n",
    "\n",
    "            word_i = curr_i - 1\n",
    "\n",
    "        curr_node = abbr_tree\n",
    "        word_i += 1\n",
    "    return \" \".join(labels)\n",
    "\n",
    "def replace_word_by_abbr(text, labels, abbr, p_replace: float = 0.2):\n",
    "    text = text.split(\" \")\n",
    "    labels = labels.split(\" \")\n",
    "    \n",
    "    new_text = []\n",
    "    new_labels = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(text):\n",
    "        label = labels[i]\n",
    "        if label == OUTSIDE_LABEL:\n",
    "            new_text.append(text[i])\n",
    "            new_labels.append(OUTSIDE_LABEL)\n",
    "\n",
    "        mode = label[0]\n",
    "\n",
    "        if mode in [ONE_WORD_LABEL, BEGIN_LABEL]:\n",
    "            abbr_id = int(label[2:])\n",
    "            replaced = random.choices([False, True], weights=[(1 - p_replace), p_replace])[0]\n",
    "            if replaced:\n",
    "                norm_abbr = abbr[abbr.abbr_id == abbr_id].abbr_norm.iloc[0].split(\" \")\n",
    "                \n",
    "                if len(norm_abbr) == 1:\n",
    "                    new_text.append(norm_abbr[0])\n",
    "                    new_labels.append(f\"{ONE_WORD_LABEL}-{str(abbr_id)}\")\n",
    "                else:\n",
    "                    new_text.append(norm_abbr[0])\n",
    "                    new_labels.append(f\"{BEGIN_LABEL}-{str(abbr_id)}\")\n",
    "                    for word in norm_abbr[1:-1]:\n",
    "                        new_text.append(word)\n",
    "                        new_labels.append(f\"{INSIDE_LABEL}-{str(abbr_id)}\")\n",
    "                    new_text.append(norm_abbr[-1])\n",
    "                    new_labels.append(f\"{END_LABEL}-{str(abbr_id)}\")\n",
    "\n",
    "            while i < len(text) and labels[i] != OUTSIDE_LABEL and int(labels[i][2:]) == abbr_id:\n",
    "                if not replaced:\n",
    "                    new_text.append(text[i])\n",
    "                    new_labels.append(OUTSIDE_LABEL)\n",
    "                i += 1\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    new_text = \" \".join(new_text)\n",
    "    new_labels = \" \".join(new_labels)\n",
    "    \n",
    "    return pd.Series({\"new_text\": new_text, \"new_labels\": new_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer(lang=\"ru\", \n",
    "                                units=[pymorphy2.units.DictionaryAnalyzer()])\n",
    "\n",
    "def norm_tokenize(line):\n",
    "    tokenized_norm = []\n",
    "    for word in word_tokenize(line):\n",
    "        parse_list = morph.parse(str(word))\n",
    "        if parse_list != []:\n",
    "            norm_form = parse_list[0].normal_form\n",
    "        else:\n",
    "            norm_form = word\n",
    "        tokenized_norm.append(norm_form)\n",
    "    return tokenized_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3eca1a1d8541668cd6328c2faf4a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=36019), Label(value='0 / 36019')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "518c8f7de07a4c1294ee261eca62bc86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=36019), Label(value='0 / 36019')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenta[\"text_tokenized\"] = lenta[\"text\"].parallel_apply(lambda x: \" \".join(word_tokenize(x)))\n",
    "lenta[\"text_norm\"] = lenta[\"text\"].parallel_apply(lambda x: \" \".join(norm_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa9399d570354b1c822160d711d14d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=36019), Label(value='0 / 36019')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenta[\"labels\"] = lenta[\"text_norm\"].parallel_apply(lambda x: get_text_labels(x, abbr_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e62df395f8450b86447bdb7de90b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=36019), Label(value='0 / 36019')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenta[[\"text_new\", \"labels_new\"]] = (\n",
    "    lenta[[\"text_norm\", \"labels\"]]\n",
    "        .parallel_apply(lambda x: replace_word_by_abbr(x[\"text_norm\"], x[\"labels\"], \n",
    "                                                       abbr, p_replace=0.3), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lenta.to_csv(\"../data/lenta_t5_v1.csv\", index=False, header=True)\n",
    "# lenta = pd.read_csv(\"../data/lenta_t5_v1.csv\", index_col=False)\n",
    "# lenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upd_text_and_labels(line):\n",
    "    text_tokenized = line.text_tokenized.split(\" \")\n",
    "    labels = line.labels.split(\" \")\n",
    "    text_new = line.text_new.split(\" \")\n",
    "    labels_new = line.labels_new.split(\" \")\n",
    "    i, j = 0, 0\n",
    "    text_upd = []\n",
    "    labels_upd = []\n",
    "    while i < len(text_tokenized) and j < len(text_new):\n",
    "        label = labels[i]\n",
    "        label_new = labels_new[j]\n",
    "\n",
    "        if label_new == \"_\" or label == \"_\":\n",
    "            text_upd.append(text_tokenized[i])\n",
    "            labels_upd.append(\"_\")\n",
    "            i += 1\n",
    "            j += 1        \n",
    "        else:\n",
    "            abbr_id = label_new.split(\"-\")[1]\n",
    "            text_upd.append(text_new[j])\n",
    "            j += 1\n",
    "            desc_list = []\n",
    "            while i < len(text_tokenized) and labels[i] != \"_\" and labels[i].split(\"-\")[1] == abbr_id:\n",
    "                desc_list.append(text_tokenized[i])\n",
    "                i += 1\n",
    "            labels_upd.append(\"=\".join(desc_list))\n",
    "    return pd.Series({\"text_upd\": \" \".join(text_upd), \"labels_upd\": \" \".join(labels_upd)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1a0f47b35b46b5817d71a59e8b106a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=36019), Label(value='0 / 36019')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenta[[\"text_upd\", \"labels_upd\"]] = (\n",
    "    lenta.parallel_apply(get_upd_text_and_labels, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lenta_filt = lenta[[\"text_upd\", \"labels_upd\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_train, lenta_test = train_test_split(lenta_filt, test_size=0.2, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenta_train.to_csv(\"../data/lenta_train_t5.csv\", index=False, header=True)\n",
    "lenta_test.to_csv(\"../data/lenta_test_t5.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
